"""
Train a neural network on PCSE inputs/outputs.

Example:
    %run nn/testnn.py outputs/RDMSOL -v
"""
from matplotlib import pyplot as plt
from tqdm import tqdm

from torch import nn, optim, tensor, Tensor
from torch.utils.data import DataLoader, Dataset

import fpcup
from fpcup.typing import PathOrStr

from dataset import PCSEEnsembleDataset
from network import PCSEEmulator, device, train

### Parse command line arguments
import argparse
parser = argparse.ArgumentParser(description="Analyse a PCSE ensemble with one varying parameter, as generated by wofost_ensemble_parameters.py.")
parser.add_argument("output_dir", help="folder to load PCSE outputs from", type=fpcup.io.Path)
parser.add_argument("--results_dir", help="folder to save plots into", type=fpcup.io.Path, default=fpcup.DEFAULT_RESULTS/"sensitivity")
parser.add_argument("-v", "--verbose", help="increase output verbosity", action="store_true")
args = parser.parse_args()


### Constants
lossfunc = nn.L1Loss()


### This gets executed only when the script is run normally; not by multiprocessing.
if __name__ == "__main__":
    fpcup.multiprocessing.freeze_support()

    ### SETUP
    # Data
    data = PCSEEnsembleDataset(args.output_dir)
    dataloader = DataLoader(data, batch_size=64, shuffle=True)

    # Network
    model = PCSEEmulator().to(device)
    optimizer = optim.Adam(model.parameters(), lr=1e-3)

    # Train
    losses = train(model, dataloader, lossfunc, optimizer, n_epochs=10)

    # Plot losses
    plt.plot(losses)

    plt.xlim(0, len(losses)+1)
    plt.ylim(ymin=0)

    plt.xlabel("Batch")
    plt.ylabel("Loss")
    plt.grid(True, ls="--")

    plt.savefig("nn_loss.pdf")
    plt.close()
